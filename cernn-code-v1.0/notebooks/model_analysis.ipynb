{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054310df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "import pickle\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"..\")))\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), \"../src/\")))\n",
    "\n",
    "\n",
    "from src.pytorch_models import LightningRNNModule\n",
    "\n",
    "from src.dataset import YangTasks\n",
    "from torch.utils.data import DataLoader\n",
    "from src.dataset import collate_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30bce17",
   "metadata": {},
   "source": [
    "# Load models \n",
    "Models should be stored as a checkpoint folder with \n",
    "``` \n",
    "checkpoint_dir \n",
    "|- epoch_perf_.ckpt   # best performing model \n",
    "|- hp_pl_module.pkl   # model hyperparameters\n",
    "|- last.ckpt          # final model after full training \n",
    "|- task_hp.pkl        # task hyperparameters \n",
    "``` \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fdcbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = \"saved_models/cernn/floral-spaceship-693_contextdelaydm1_contextdelaydm2_V1_5_FEF_5_3b_5\"\n",
    "\n",
    "with open(\n",
    "    f\"../{checkpoint_dir}/hp_pl_module.pkl\",\n",
    "    \"rb\",\n",
    ") as file:\n",
    "    hp_pl_module = pickle.load(file)\n",
    "\n",
    "with open(\n",
    "    f\"../{checkpoint_dir}/task_hp.pkl\",\n",
    "    \"rb\",\n",
    ") as file:\n",
    "    task_hp = pickle.load(file)\n",
    "\n",
    "# load last model by default\n",
    "pretrained_model = LightningRNNModule.load_from_checkpoint(\n",
    "    f\"../{checkpoint_dir}/last.ckpt\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18a878b",
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c254fda5",
   "metadata": {},
   "source": [
    "### Recurrent weight matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2b3751",
   "metadata": {},
   "outputs": [],
   "source": [
    "recurrent_weights = pretrained_model.model.rnn.rnncell.weight_hh.detach().cpu().numpy()\n",
    "recurrent_weights.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282d4bac",
   "metadata": {},
   "source": [
    "## Regularisers with values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42ffed81",
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint(dict(hp_pl_module.regularisers))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49cbc74d",
   "metadata": {},
   "source": [
    "# Cortical embedding object with CE info \n",
    "E.g. \n",
    "```\n",
    "cortical_areas\n",
    "duplicates \n",
    "distance_matrix\n",
    "sensory and motor areas \n",
    "dmn_areas\n",
    "```\n",
    "and values used for this model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9161e783",
   "metadata": {},
   "outputs": [],
   "source": [
    "cortical_embeddign = pretrained_model.model.ce\n",
    "vars(cortical_embeddign)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c295857e",
   "metadata": {},
   "source": [
    "## Corresponding dataset and dataloader\n",
    "This is useful for activity analysis but not for connectivity\n",
    "\n",
    "Input dimension is 2 rings x 2 dims per ring + 26 task IDs + 1 fixation = 31 \n",
    "\n",
    "Ouput dimension is 2 dims per ring + 1 fixation = 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82021991",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_test = YangTasks(task_hp, mode=\"test\")\n",
    "\n",
    "dataloader_test = DataLoader(\n",
    "    dataset_test,\n",
    "    batch_size=1,  # batch size 1 here because we need all trials in batch to be same task/rule\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=0,\n",
    "    shuffle=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95e58183",
   "metadata": {},
   "outputs": [],
   "source": [
    "trail_batch = next(iter(dataloader_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a60f046",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = trail_batch.x.squeeze(0)\n",
    "y = trail_batch.y.squeeze(0)\n",
    "\n",
    "print(x.shape)  # [Timesteps, batchsize, D_in]\n",
    "print(y.shape)  # [Timesteps, batchsize, D_out]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f294d22d",
   "metadata": {},
   "source": [
    "# Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde13d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.analysis_connectivity import (\n",
    "    fig_3_plot_connectivity_matrix,\n",
    "    fig_3_weights_over_distance_lambda_fitted,\n",
    "    fig_3_FLN_matrix,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71371490",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1 = fig_3_plot_connectivity_matrix(pretrained_model.model)\n",
    "fig2 = fig_3_FLN_matrix(pretrained_model.model)\n",
    "fig3 = fig_3_weights_over_distance_lambda_fitted(pretrained_model.model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127644c2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cernn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
